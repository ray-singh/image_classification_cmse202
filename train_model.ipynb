{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8437958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines CancerDataset class for loading in data that can interact with pytorch\n",
    "# objects like torch.utils.data.DataLoader \n",
    "\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CancerDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Abstraction representing a dataset containing the images in the Breast Histopathology Images Dataset\n",
    "    (https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images). \n",
    "    \"\"\"\n",
    "    def __init__(self, img_labels, img_paths, transform=None, target_transform=None):\n",
    "        # img-labels\n",
    "        self.img_labels = img_labels\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bcf927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.transforms import Lambda\n",
    "from torchvision.transforms.v2 import ToDtype\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "image_paths = np.array(glob.glob('/Users/calvindejong/Downloads/cancer_images/IDC_regular_ps50_idx5/**/*.png', recursive = True))\n",
    "labels = np.zeros(len(image_paths),dtype=int)\n",
    "for i in range(len(image_paths)):\n",
    "    label = image_paths[i][-5]\n",
    "    labels[i] = int(label)\n",
    "    #labels[i] = image[i][-5]\n",
    "\n",
    "img_transforms = transforms.Compose([\n",
    "    transforms.Resize((50,50)),\n",
    "    transforms.v2.ToDtype(torch.float,scale=True),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "dataset = CancerDataset(\n",
    "    img_labels=labels,\n",
    "    img_paths=image_paths,\n",
    "    transform=img_transforms,\n",
    "    target_transform=Lambda(lambda y: torch.zeros(\n",
    "    2, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    ")\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset=dataset,\n",
    "    lengths=[0.8,0.2],\n",
    "    generator=torch.Generator().manual_seed(22)\n",
    ")\n",
    "    \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "data, _  = next(iter(train_dataloader))\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Abstraction representing a feedforward neural network that can be trained to accurately predict \n",
    "    whether IDC is present in a 50x50x3 pixel image\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\" \n",
    "        Defines the neural network's component layers as a flatten layer followed \n",
    "        by linear layers of 7500, 1000, 100, and 2 nodes with ReLU functions separating each.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(50*50*3, 1000),\n",
    "            nn.ReLU(), # f(x) = max(0,x)\n",
    "            nn.Linear(1000, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the routine that transforms input image into output prediction. Returns raw logits (pre softmax)\n",
    "        \"\"\"\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Loops through the entire training dataset, computing the model's prediction, performing back prop, \n",
    "    and updating the parameters for each batch of 64 images.\n",
    "    \n",
    "    Parameters:\n",
    "    dataloader - a pytorch DataLoader object holding the training data\n",
    "    model - a NeuralNetwork object (see above)\n",
    "    loss_fn - a pytorch loss function (eg nn.CrossEntropyLoss)\n",
    "    optimizer - a pytorch optimizer (eg torch.optim.SGD)\n",
    "    \n",
    "    Returns:\n",
    "    nothing\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    \"\"\"\n",
    "    Loops through the entire test dataset, computing the model's predictions and printing the test error,\n",
    "    accuracy, and average loss the model achieved\n",
    "    \n",
    "    Parameters:\n",
    "    dataloader - a pytorch DataLoader object holding the test data\n",
    "    model - a NeuralNetwork object that has undergone at least one iteration of train_loop()\n",
    "    loss_fn - a pytorch loss function (eg nn.CrossEntropyLoss)\n",
    "    \n",
    "    Returns:\n",
    "    nothing\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y.argmax(1)).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done training\")\n",
    "\n",
    "# Save model\n",
    "\n",
    "torch.save(model.state_dict(), 'model_weights.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
